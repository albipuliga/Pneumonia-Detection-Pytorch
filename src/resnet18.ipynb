{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-zKKdCwZPHi"
   },
   "source": [
    "# Pneumonia Detection with PyTorch & ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWV1-asBZPHi"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqCdhsA9n0tX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW1nGCf-ZPHj"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01RoWA9Ioa-q"
   },
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "PATIENCE = 5\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "TARGET_SENSITIVITY = 0.95\n",
    "\n",
    "\n",
    "def locate_project_src_dir() -> Path:\n",
    "    candidates = [\n",
    "        Path(\"src\"),\n",
    "        Path(\".\"),\n",
    "        Path(\"../src\"),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        c = c.resolve()\n",
    "        if c.name == \"src\" and c.exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(\"Could not locate project src directory.\")\n",
    "\n",
    "\n",
    "def locate_data_dir() -> Path:\n",
    "    candidates = [\n",
    "        Path(\"../data\"),\n",
    "        Path(\"data\"),\n",
    "        Path.cwd() / \"../data\",\n",
    "        Path.cwd() / \"data\",\n",
    "        locate_project_src_dir().parent / \"data\",\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        c = c.resolve()\n",
    "        if (c / \"train\" / \"NORMAL\").exists() and (c / \"train\" / \"PNEUMONIA\").exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(\"Could not locate data directory with train/NORMAL and train/PNEUMONIA.\")\n",
    "\n",
    "\n",
    "SRC_DIR = locate_project_src_dir()\n",
    "RAW_DATA_DIR = locate_data_dir()\n",
    "MODEL_DIR = SRC_DIR / \"models\"\n",
    "\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if hasattr(torch.backends, \"cudnn\"):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def resolve_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "seed_everything(SEED)\n",
    "device = resolve_device()\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Resolved SRC_DIR: {SRC_DIR}\")\n",
    "print(f\"Resolved RAW_DATA_DIR: {RAW_DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxfYM1S5ZPHj"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHVdON0hofdp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_patient_id(file_name: str, label: str) -> str:\n",
    "    stem = Path(file_name).stem\n",
    "    if label == \"PNEUMONIA\":\n",
    "        m = re.match(r\"^(person\\d+)\", stem)\n",
    "        return m.group(1) if m else stem\n",
    "\n",
    "    m = re.match(r\"^(NORMAL2-IM-\\d+|IM-\\d+)\", stem)\n",
    "    return m.group(1) if m else stem\n",
    "\n",
    "\n",
    "def parse_pneumonia_type(file_name: str, label: str) -> str:\n",
    "    if label != \"PNEUMONIA\":\n",
    "        return \"none\"\n",
    "    lower_name = file_name.lower()\n",
    "    if \"_bacteria_\" in lower_name:\n",
    "        return \"bacteria\"\n",
    "    if \"_virus_\" in lower_name:\n",
    "        return \"virus\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def discover_records(raw_data_dir: Path):\n",
    "    records = []\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for label in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "            class_dir = raw_data_dir / split / label\n",
    "            for img_path in sorted(class_dir.iterdir()):\n",
    "                if not img_path.is_file() or img_path.name.startswith(\".\"):\n",
    "                    continue\n",
    "                patient_id = parse_patient_id(img_path.name, label)\n",
    "                pneumonia_type = parse_pneumonia_type(img_path.name, label)\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"image_path\": str(img_path),\n",
    "                        \"label\": label,\n",
    "                        \"label_idx\": 0 if label == \"NORMAL\" else 1,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"pneumonia_type\": pneumonia_type,\n",
    "                        \"original_split\": split,\n",
    "                        \"group_key\": (label, patient_id),\n",
    "                    }\n",
    "                )\n",
    "    records.sort(key=lambda r: (r[\"label\"], r[\"patient_id\"], r[\"image_path\"]))\n",
    "    return records\n",
    "\n",
    "\n",
    "def overlap_counts_by_split(records):\n",
    "    split_ids = {\n",
    "        split: {\n",
    "            r[\"patient_id\"]\n",
    "            for r in records\n",
    "            if r[\"original_split\"] == split and r[\"label\"] == \"PNEUMONIA\"\n",
    "        }\n",
    "        for split in [\"train\", \"val\", \"test\"]\n",
    "    }\n",
    "    return {\n",
    "        \"train_val\": len(split_ids[\"train\"] & split_ids[\"val\"]),\n",
    "        \"train_test\": len(split_ids[\"train\"] & split_ids[\"test\"]),\n",
    "        \"val_test\": len(split_ids[\"val\"] & split_ids[\"test\"]),\n",
    "    }, split_ids\n",
    "\n",
    "\n",
    "def split_bucket(keys, ratios, rng):\n",
    "    keys = list(keys)\n",
    "    rng.shuffle(keys)\n",
    "    n = len(keys)\n",
    "    if n == 0:\n",
    "        return set(), set(), set()\n",
    "    if n == 1:\n",
    "        return set(keys), set(), set()\n",
    "    if n == 2:\n",
    "        return {keys[0]}, {keys[1]}, set()\n",
    "\n",
    "    train_ratio, val_ratio, test_ratio = ratios\n",
    "    n_test = max(1, int(round(n * test_ratio)))\n",
    "    n_val = max(1, int(round(n * val_ratio)))\n",
    "\n",
    "    # Keep at least one train patient.\n",
    "    while n_test + n_val > n - 1:\n",
    "        if n_test >= n_val and n_test > 1:\n",
    "            n_test -= 1\n",
    "        elif n_val > 1:\n",
    "            n_val -= 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    n_train = n - n_val - n_test\n",
    "    train_keys = set(keys[:n_train])\n",
    "    val_keys = set(keys[n_train : n_train + n_val])\n",
    "    test_keys = set(keys[n_train + n_val :])\n",
    "    return train_keys, val_keys, test_keys\n",
    "\n",
    "\n",
    "def split_by_patient(records, ratios=(0.8, 0.1, 0.1), seed=42):\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    group_to_records = {}\n",
    "    for r in records:\n",
    "        group_to_records.setdefault(r[\"group_key\"], []).append(r)\n",
    "\n",
    "    normal_keys = [k for k in group_to_records if k[0] == \"NORMAL\"]\n",
    "\n",
    "    pneumonia_groups = {}\n",
    "    for k, recs in group_to_records.items():\n",
    "        if k[0] != \"PNEUMONIA\":\n",
    "            continue\n",
    "        subtypes = sorted({rec[\"pneumonia_type\"] for rec in recs if rec[\"pneumonia_type\"] != \"unknown\"})\n",
    "        if len(subtypes) == 0:\n",
    "            bucket = \"unknown\"\n",
    "        elif len(subtypes) == 1:\n",
    "            bucket = subtypes[0]\n",
    "        else:\n",
    "            bucket = \"mixed\"\n",
    "        pneumonia_groups.setdefault(bucket, []).append(k)\n",
    "\n",
    "    train_keys, val_keys, test_keys = set(), set(), set()\n",
    "\n",
    "    t, v, te = split_bucket(normal_keys, ratios, rng)\n",
    "    train_keys |= t\n",
    "    val_keys |= v\n",
    "    test_keys |= te\n",
    "\n",
    "    for _, bucket_keys in sorted(pneumonia_groups.items()):\n",
    "        t, v, te = split_bucket(bucket_keys, ratios, rng)\n",
    "        train_keys |= t\n",
    "        val_keys |= v\n",
    "        test_keys |= te\n",
    "\n",
    "    split_records = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    for k, recs in group_to_records.items():\n",
    "        if k in train_keys:\n",
    "            split_records[\"train\"].extend(recs)\n",
    "        elif k in val_keys:\n",
    "            split_records[\"val\"].extend(recs)\n",
    "        elif k in test_keys:\n",
    "            split_records[\"test\"].extend(recs)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Group key {k} was not assigned to any split.\")\n",
    "\n",
    "    for split in split_records:\n",
    "        split_records[split].sort(key=lambda r: (r[\"label\"], r[\"patient_id\"], r[\"image_path\"]))\n",
    "\n",
    "    return split_records\n",
    "\n",
    "\n",
    "def summarize_splits(split_records):\n",
    "    summary = {}\n",
    "    for split, recs in split_records.items():\n",
    "        by_label = {\"NORMAL\": 0, \"PNEUMONIA\": 0}\n",
    "        by_subtype = {\"bacteria\": 0, \"virus\": 0, \"unknown\": 0}\n",
    "        for r in recs:\n",
    "            by_label[r[\"label\"]] += 1\n",
    "            if r[\"label\"] == \"PNEUMONIA\":\n",
    "                by_subtype[r[\"pneumonia_type\"]] = by_subtype.get(r[\"pneumonia_type\"], 0) + 1\n",
    "        summary[split] = {\n",
    "            \"total\": len(recs),\n",
    "            \"by_label\": by_label,\n",
    "            \"pneumonia_subtypes\": by_subtype,\n",
    "            \"unique_patients\": len({r[\"group_key\"] for r in recs}),\n",
    "        }\n",
    "    return summary\n",
    "\n",
    "\n",
    "def assert_split_integrity(split_records, all_records):\n",
    "    split_keys = {\n",
    "        split: {r[\"group_key\"] for r in recs}\n",
    "        for split, recs in split_records.items()\n",
    "    }\n",
    "\n",
    "    overlap_train_val = split_keys[\"train\"] & split_keys[\"val\"]\n",
    "    overlap_train_test = split_keys[\"train\"] & split_keys[\"test\"]\n",
    "    overlap_val_test = split_keys[\"val\"] & split_keys[\"test\"]\n",
    "\n",
    "    if overlap_train_val or overlap_train_test or overlap_val_test:\n",
    "        raise RuntimeError(\"Patient leakage detected after patient-level split.\")\n",
    "\n",
    "    for split in [\"val\", \"test\"]:\n",
    "        labels = [r[\"label\"] for r in split_records[split]]\n",
    "        if \"NORMAL\" not in labels or \"PNEUMONIA\" not in labels:\n",
    "            raise RuntimeError(f\"Split '{split}' is missing one class.\")\n",
    "\n",
    "    global_p_types = {\n",
    "        r[\"pneumonia_type\"]\n",
    "        for r in all_records\n",
    "        if r[\"label\"] == \"PNEUMONIA\" and r[\"pneumonia_type\"] in {\"bacteria\", \"virus\"}\n",
    "    }\n",
    "    for split in [\"val\", \"test\"]:\n",
    "        split_types = {\n",
    "            r[\"pneumonia_type\"]\n",
    "            for r in split_records[split]\n",
    "            if r[\"label\"] == \"PNEUMONIA\" and r[\"pneumonia_type\"] in {\"bacteria\", \"virus\"}\n",
    "        }\n",
    "        if global_p_types == {\"bacteria\", \"virus\"} and split_types != {\"bacteria\", \"virus\"}:\n",
    "            raise RuntimeError(\n",
    "                f\"Split '{split}' does not include both bacterial and viral pneumonia. Found: {split_types}\"\n",
    "            )\n",
    "\n",
    "\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, records, transform=None):\n",
    "        self.records = records\n",
    "        self.transform = transform\n",
    "        self.labels = [r[\"label_idx\"] for r in records]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.records[idx]\n",
    "        image = Image.open(record[\"image_path\"]).convert(\"RGB\")\n",
    "        label = record[\"label_idx\"]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qShPAiXGZPHk"
   },
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI-yDEqhoj5C"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIAC9CM226mf"
   },
   "outputs": [],
   "source": [
    "\n",
    "all_records = discover_records(RAW_DATA_DIR)\n",
    "orig_overlap_counts, orig_split_ids = overlap_counts_by_split(all_records)\n",
    "\n",
    "print(\"Original Kaggle split pneumonia patient overlaps:\")\n",
    "for k, v in orig_overlap_counts.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "split_records = split_by_patient(\n",
    "    all_records,\n",
    "    ratios=(TRAIN_RATIO, VAL_RATIO, TEST_RATIO),\n",
    "    seed=SEED,\n",
    ")\n",
    "assert_split_integrity(split_records, all_records)\n",
    "split_summary = summarize_splits(split_records)\n",
    "\n",
    "print(\"\\nPatient-safe split summary:\")\n",
    "for split, info in split_summary.items():\n",
    "    print(f\"[{split}] total={info['total']} unique_patients={info['unique_patients']}\")\n",
    "    print(f\"  labels: {info['by_label']}\")\n",
    "    print(f\"  pneumonia_subtypes: {info['pneumonia_subtypes']}\")\n",
    "\n",
    "train_records = split_records[\"train\"]\n",
    "val_records = split_records[\"val\"]\n",
    "test_records = split_records[\"test\"]\n",
    "\n",
    "train_dataset = PneumoniaDataset(records=train_records, transform=train_transform)\n",
    "val_dataset = PneumoniaDataset(records=val_records, transform=eval_transform)\n",
    "test_dataset = PneumoniaDataset(records=test_records, transform=eval_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEBF_IAWbm1g"
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W82Jw4CDboJo",
    "outputId": "1ca82146-453d-43e8-b200-7396db0048e9"
   },
   "outputs": [],
   "source": [
    "\n",
    "split_datasets = {\n",
    "    \"Train\": train_dataset,\n",
    "    \"Validation\": val_dataset,\n",
    "    \"Test\": test_dataset,\n",
    "}\n",
    "class_names = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for idx, (split_name, dataset) in enumerate(split_datasets.items()):\n",
    "    labels = np.array(dataset.labels)\n",
    "    counts = np.bincount(labels, minlength=2)\n",
    "    ax = axes[idx]\n",
    "    ax.pie(\n",
    "        counts,\n",
    "        labels=class_names,\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "        colors=[\"#4e79a7\", \"#f28e2b\"],\n",
    "    )\n",
    "    ax.set_title(f\"{split_name} Set\\nn={counts.sum()}\")\n",
    "\n",
    "plt.suptitle(\"Class Distribution by Patient-Safe Split\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "GtS0nTUPbqV6",
    "outputId": "d3ab2fb9-1305-4b66-c5e5-32fbe308a5ab"
   },
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "labels_array = np.array(train_dataset.labels)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "for row, label in enumerate([0, 1]):\n",
    "    indices = np.where(labels_array == label)[0]\n",
    "    chosen = rng.choice(indices, size=min(5, len(indices)), replace=False)\n",
    "\n",
    "    for col in range(5):\n",
    "        ax = axes[row, col]\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        if col >= len(chosen):\n",
    "            continue\n",
    "\n",
    "        idx = chosen[col]\n",
    "        with Image.open(train_dataset.records[idx][\"image_path\"]) as img:\n",
    "            ax.imshow(img.convert(\"L\"), cmap=\"gray\")\n",
    "\n",
    "        ax.set_title(f\"{class_names[label]} #{col + 1}\", fontsize=10)\n",
    "\n",
    "fig.suptitle(\"Random training samples by class\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhA9_frh29sq",
    "outputId": "35e00635-7e85-4fef-c3de-d94c7f90ddcd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Class-weighted loss only (no weighted sampler) to avoid double correction.\n",
    "train_labels = np.array(train_dataset.labels)\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = len(train_labels) / (2.0 * class_counts)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=(device.type != \"cpu\"),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=(device.type != \"cpu\"),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=(device.type != \"cpu\"),\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")\n",
    "print(f\"Class distribution (train): Normal={class_counts[0]}, Pneumonia={class_counts[1]}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmR3v0M7ZPHk"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3rpb44Combi"
   },
   "outputs": [],
   "source": [
    "# Freeze early layers, fine-tune later ones\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze all layers first\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze layer3, layer4, and fc\n",
    "for name, param in model.named_parameters():\n",
    "    if any(s in name for s in [\"layer3\", \"layer4\", \"fc\"]):\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(model.fc.in_features, 2))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCSP-cio3EA1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loss with class weights + Optimizer + Scheduler\n",
    "weight_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Use a threshold-independent validation objective for LR scheduling and checkpointing.\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deCkrTWCZPHl"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4clwamijoo6m",
    "outputId": "a6d4183a-7739-43fa-e109-49d8ada001cf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def safe_auc_roc(y_true, y_prob):\n",
    "    return roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float(\"nan\")\n",
    "\n",
    "\n",
    "def safe_auc_pr(y_true, y_prob):\n",
    "    return average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float(\"nan\")\n",
    "\n",
    "\n",
    "best_val_metric = -np.inf\n",
    "best_model_state = copy.deepcopy(model.state_dict())\n",
    "best_val_labels = None\n",
    "best_val_probs = None\n",
    "epochs_no_improve = 0\n",
    "history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / max(1, len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_labels_list, val_probs_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            val_labels_list.extend(labels.cpu().numpy())\n",
    "            val_probs_list.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_val = np.array(val_labels_list)\n",
    "    p_val = np.array(val_probs_list)\n",
    "    y_val_pred_05 = (p_val >= 0.5).astype(int)\n",
    "\n",
    "    val_acc = accuracy_score(y_val, y_val_pred_05)\n",
    "    val_f1 = f1_score(y_val, y_val_pred_05, zero_division=0)\n",
    "    val_auc_pr = safe_auc_pr(y_val, p_val)\n",
    "    val_auc_roc = safe_auc_roc(y_val, p_val)\n",
    "\n",
    "    val_metric = val_auc_pr if not np.isnan(val_auc_pr) else val_acc\n",
    "    scheduler.step(val_metric)\n",
    "\n",
    "    history.append(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": float(avg_loss),\n",
    "            \"val_acc_at_0.5\": float(val_acc),\n",
    "            \"val_f1_at_0.5\": float(val_f1),\n",
    "            \"val_auc_pr\": None if np.isnan(val_auc_pr) else float(val_auc_pr),\n",
    "            \"val_auc_roc\": None if np.isnan(val_auc_roc) else float(val_auc_roc),\n",
    "            \"val_metric\": float(val_metric),\n",
    "            \"lr\": float(optimizer.param_groups[0][\"lr\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{EPOCHS} | Loss: {avg_loss:.4f} | \"\n",
    "        f\"Val AUPRC: {val_auc_pr:.4f} | Val AUROC: {val_auc_roc:.4f} | \"\n",
    "        f\"Val Acc@0.5: {val_acc:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "    )\n",
    "\n",
    "    if val_metric > best_val_metric + 1e-8:\n",
    "        best_val_metric = val_metric\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        best_val_labels = y_val.copy()\n",
    "        best_val_probs = p_val.copy()\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  -> New best model saved (val_metric={val_metric:.4f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "if best_model_state is None:\n",
    "    raise RuntimeError(\"best_model_state was not set. Training checkpointing failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyrwbHK7ZPHl"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eH_lhlWZoq3_",
    "outputId": "4a1a23e6-3418-4d6e-b2f9-e8e1872810d7"
   },
   "outputs": [],
   "source": [
    "def confusion_elements(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "\n",
    "def threshold_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_elements(y_true, y_pred)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"ppv\": ppv,\n",
    "        \"npv\": npv,\n",
    "    }\n",
    "\n",
    "\n",
    "def choose_threshold(y_true, y_prob, target_sensitivity=0.95):\n",
    "    thresholds = np.linspace(0.0, 1.0, 1001)\n",
    "    candidates = []\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_prob >= t).astype(int)\n",
    "        m = threshold_metrics(y_true, y_pred)\n",
    "        candidates.append((float(t), m))\n",
    "\n",
    "    feasible = [x for x in candidates if x[1][\"sensitivity\"] >= target_sensitivity]\n",
    "    if feasible:\n",
    "        best_t, best_m = max(feasible, key=lambda x: (x[1][\"f1\"], x[1][\"specificity\"]))\n",
    "        policy = \"sensitivity_constrained\"\n",
    "    else:\n",
    "        best_t, best_m = max(candidates, key=lambda x: (x[1][\"f1\"], x[1][\"sensitivity\"]))\n",
    "        policy = \"f1_fallback\"\n",
    "\n",
    "    return best_t, best_m, policy\n",
    "\n",
    "\n",
    "def bootstrap_cis(y_true, y_prob, threshold, n_boot=500, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    stats = {k: [] for k in [\"accuracy\", \"f1\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\", \"roc_auc\", \"pr_auc\"]}\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        y_b = y_true[idx]\n",
    "        p_b = y_prob[idx]\n",
    "        y_pred_b = (p_b >= threshold).astype(int)\n",
    "\n",
    "        m = threshold_metrics(y_b, y_pred_b)\n",
    "        for k in [\"accuracy\", \"f1\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\"]:\n",
    "            stats[k].append(m[k])\n",
    "\n",
    "        if len(np.unique(y_b)) > 1:\n",
    "            stats[\"roc_auc\"].append(roc_auc_score(y_b, p_b))\n",
    "            stats[\"pr_auc\"].append(average_precision_score(y_b, p_b))\n",
    "\n",
    "    cis = {}\n",
    "    for k, vals in stats.items():\n",
    "        if len(vals) == 0:\n",
    "            cis[k] = {\"lower\": None, \"upper\": None}\n",
    "        else:\n",
    "            lo, hi = np.percentile(vals, [2.5, 97.5])\n",
    "            cis[k] = {\"lower\": float(lo), \"upper\": float(hi)}\n",
    "    return cis\n",
    "\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def collect_logits_labels(loader, model, device):\n",
    "    all_logits, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    return torch.cat(all_logits, dim=0), torch.cat(all_labels, dim=0)\n",
    "\n",
    "\n",
    "val_logits_t, val_labels_t = collect_logits_labels(val_loader, model, device)\n",
    "test_logits_t, test_labels_t = collect_logits_labels(test_loader, model, device)\n",
    "print(\"val logits:\", tuple(val_logits_t.shape), \"test logits:\", tuple(test_logits_t.shape))\n",
    "\n",
    "\n",
    "def fit_temperature(val_logits, val_labels, max_iter=200):\n",
    "    log_t = torch.nn.Parameter(torch.zeros(1))\n",
    "    nll = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(\n",
    "        [log_t], lr=0.1, max_iter=max_iter, line_search_fn=\"strong_wolfe\"\n",
    "    )\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.exp(log_t).clamp(1e-3, 100.0)\n",
    "        loss = nll(val_logits / t, val_labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    return float(torch.exp(log_t).clamp(1e-3, 100.0).item())\n",
    "\n",
    "\n",
    "temperature = fit_temperature(val_logits_t, val_labels_t)\n",
    "print(f\"Learned temperature: {temperature:.6f}\")\n",
    "\n",
    "val_prob_raw = torch.softmax(val_logits_t, dim=1)[:, 1].numpy()\n",
    "val_prob_cal = torch.softmax(val_logits_t / temperature, dim=1)[:, 1].numpy()\n",
    "val_y = val_labels_t.numpy()\n",
    "\n",
    "val_nll_raw = F.cross_entropy(val_logits_t, val_labels_t).item()\n",
    "val_nll_cal = F.cross_entropy(val_logits_t / temperature, val_labels_t).item()\n",
    "val_brier_raw = brier_score_loss(val_y, val_prob_raw)\n",
    "val_brier_cal = brier_score_loss(val_y, val_prob_cal)\n",
    "\n",
    "print(f\"Val NLL raw/cal:   {val_nll_raw:.6f} -> {val_nll_cal:.6f}\")\n",
    "print(f\"Val Brier raw/cal: {val_brier_raw:.6f} -> {val_brier_cal:.6f}\")\n",
    "\n",
    "best_val_labels = val_labels_t.numpy()\n",
    "best_val_probs = torch.softmax(val_logits_t / temperature, dim=1)[:, 1].numpy()\n",
    "\n",
    "selected_threshold, val_threshold_metrics, threshold_policy = choose_threshold(\n",
    "    best_val_labels,\n",
    "    best_val_probs,\n",
    "    target_sensitivity=TARGET_SENSITIVITY,\n",
    ")\n",
    "\n",
    "print(f\"Selected threshold: {selected_threshold:.3f} (policy={threshold_policy})\")\n",
    "print(f\"Validation metrics at selected threshold: {val_threshold_metrics}\")\n",
    "\n",
    "# Evaluate on calibrated test probabilities\n",
    "y_true = test_labels_t.numpy()\n",
    "y_prob = torch.softmax(test_logits_t / temperature, dim=1)[:, 1].numpy()\n",
    "y_pred = (y_prob >= selected_threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "auc_roc = safe_auc_roc(y_true, y_prob)\n",
    "auc_pr = safe_auc_pr(y_true, y_prob)\n",
    "brier = brier_score_loss(y_true, y_prob)\n",
    "thresholded = threshold_metrics(y_true, y_pred)\n",
    "ci = bootstrap_cis(y_true, y_prob, selected_threshold, n_boot=500, seed=SEED)\n",
    "\n",
    "print(\"Test set performance (calibrated)\")\n",
    "print(f\"Threshold: {selected_threshold:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 score: {f1:.4f}\")\n",
    "print(f\"Sensitivity: {thresholded['sensitivity']:.4f}\")\n",
    "print(f\"Specificity: {thresholded['specificity']:.4f}\")\n",
    "print(f\"PPV: {thresholded['ppv']:.4f}\")\n",
    "print(f\"NPV: {thresholded['npv']:.4f}\")\n",
    "print(f\"ROC-AUC:  {auc_roc:.4f}\")\n",
    "print(f\"PR-AUC:   {auc_pr:.4f}\")\n",
    "print(f\"Brier:    {brier:.4f}\")\n",
    "print()\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"NORMAL\", \"PNEUMONIA\"], zero_division=0))\n",
    "\n",
    "print(\"\\n95% bootstrap CI:\")\n",
    "for k, v in ci.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jW5I3nTRcDRn"
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "R1n7RJt-cElK",
    "outputId": "14417000-f93c-4cbf-ef11-bd21a5474a85"
   },
   "outputs": [],
   "source": [
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_prob)\n",
    "cm_norm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "im = axes[0].imshow(cm_norm, cmap=\"Oranges\", vmin=0, vmax=1)\n",
    "for i in range(cm_norm.shape[0]):\n",
    "    for j in range(cm_norm.shape[1]):\n",
    "        axes[0].text(j, i, f\"{cm_norm[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_xticklabels([\"NORMAL\", \"PNEUMONIA\"])\n",
    "axes[0].set_yticklabels([\"NORMAL\", \"PNEUMONIA\"])\n",
    "axes[0].set_title(f\"Normalized confusion matrix\\n(threshold={selected_threshold:.2f})\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"True\")\n",
    "fig.colorbar(im, ax=axes[0], fraction=0.046)\n",
    "\n",
    "axes[1].plot(fpr, tpr, label=f\"ROC-AUC = {auc_roc:.3f}\", color=\"#2C7FB8\")\n",
    "axes[1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "axes[1].set_title(\"ROC curve\")\n",
    "axes[1].set_xlabel(\"False positive rate\")\n",
    "axes[1].set_ylabel(\"True positive rate\")\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "axes[2].plot(recall_curve, precision_curve, label=f\"PR-AUC = {auc_pr:.3f}\", color=\"#41AB5D\")\n",
    "axes[2].set_title(\"Precision-Recall curve\")\n",
    "axes[2].set_xlabel(\"Recall\")\n",
    "axes[2].set_ylabel(\"Precision\")\n",
    "axes[2].legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGE_7th6ZPHl"
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZN_p7FahosOm"
   },
   "outputs": [],
   "source": [
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = MODEL_DIR / \"model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Saved model to: {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}